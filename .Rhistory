library(corrplot)
library(reshape)
install.packages("reshape")
#Load libraries
library(tidyverse)
library(plm)
library(tidyr)
library(ggplot2)
library(scales)
library(readstata13)
library(corrplot)
library(reshape)
library(dplyr)
library(corrplot)
library(gridExtra)
library(rpart)
library(partykit)
install.packages("partykit")
#Load libraries
library(tidyverse)
library(plm)
library(tidyr)
library(ggplot2)
library(scales)
library(readstata13)
library(corrplot)
library(reshape)
library(dplyr)
library(corrplot)
library(gridExtra)
library(rpart)
library(partykit)
library(caret)
library(mlbench)
library(tidyverse)
library(rminer)
library(randomForest)
library(reshape2)
library(MASS)
library(e1071)
library(wsrf)
library(kernlab)
# set working directory and import data
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
spamdata <- read.csv("spambase.data", header=FALSE)
dim(spamdata)
glimpse(spamdata)
# Find NA per Column
if (sum(is.na(spamdata)) == 0) {
print(paste("The count of NA in dataset =", sum(is.na(spamdata))))
} else {
cnt <- ncol(spamdata)
for (i in 1:cnt) {
print(colnames(spamdata)[i])
print(sum(is.na(spamdata[,i])))
}
}
spamnames <- read.csv("spambase.names", header=FALSE)
View(spamnames)
#Start Fresh
rm(list=ls())
#Load libraries
library(tidyverse)
library(plm)
library(tidyr)
library(ggplot2)
library(scales)
library(readstata13)
library(corrplot)
library(reshape)
library(dplyr)
library(corrplot)
library(gridExtra)
library(rpart)
library(partykit)
library(caret)
library(mlbench)
library(tidyverse)
library(rminer)
library(randomForest)
library(reshape2)
library(MASS)
library(e1071)
library(wsrf)
library(kernlab)
# set working directory and import data
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
spamdata <- read.csv("spambase.data", header=FALSE)
dim(spamdata)
glimpse(spamdata)
# Find NA per Column
if (sum(is.na(spamdata)) == 0) {
print(paste("The count of NA in dataset =", sum(is.na(spamdata))))
} else {
cnt <- ncol(spamdata)
for (i in 1:cnt) {
print(colnames(spamdata)[i])
print(sum(is.na(spamdata[,i])))
}
}
newnames <- c("freq_make", "freq_address", "freq_all", "freq_3d", "freq_our", "freq_over", "freq_remove", "freq_internet",
"freq_order", "freq_mail", "freq_receive", "freq_will", "freq_people", "freq_report", "freq_addresses", "freq_free",
"freq_business", "freq_email", "freq_you", "freq_credit", "freq_your", "freq_font", "freq_000", "freq_money",
"freq_hp", "freq_hpl", "freq_george", "freq_650", "freq_lab", "freq_labs", "freq_telnet", "freq_857",
"freq_data", "freq_415", "freq_85", "freq_technology", "freq_1999", "freq_parts", "freq_pm", "freq_direct",
"freq_vcs", "freq_meeting", "freq_original", "freq_project", "freq_re", "freq_edu", "freq_table", "freq_conference",
"freq_semicolon", "freq_parentheses", "freq_bracket", "freq_exclamation_point", "freq_dollar_sign", "freq_pound_sign",
"caps_len_average", "caps_len_longest", "caps_len_total", "spam")
names(spamdata) <- newnames
spamdata$caps_len_longest <- as.double(spamdata$caps_len_longest)
spamdata$caps_len_total <- as.double(spamdata$caps_len_total)
spamdata <- spamdata %>% dplyr::select(spam,everything())
spamdata$spam <- as.factor(ifelse(spamdata$spam==1,"Y","N"))
newnames <- c("freq_make", "freq_address", "freq_all", "freq_3d", "freq_our", "freq_over", "freq_remove", "freq_internet",
"freq_order", "freq_mail", "freq_receive", "freq_will", "freq_people", "freq_report", "freq_addresses", "freq_free",
"freq_business", "freq_email", "freq_you", "freq_credit", "freq_your", "freq_font", "freq_000", "freq_money",
"freq_hp", "freq_hpl", "freq_george", "freq_650", "freq_lab", "freq_labs", "freq_telnet", "freq_857",
"freq_data", "freq_415", "freq_85", "freq_technology", "freq_1999", "freq_parts", "freq_pm", "freq_direct",
"freq_vcs", "freq_meeting", "freq_original", "freq_project", "freq_re", "freq_edu", "freq_table", "freq_conference",
"freq_semicolon", "freq_parentheses", "freq_bracket", "freq_exclamation_point", "freq_dollar_sign", "freq_pound_sign",
"caps_len_average", "caps_len_longest", "caps_len_total", "spam")
names(spamdata) <- newnames
spamdata$caps_len_longest <- as.double(spamdata$caps_len_longest)
spamdata$caps_len_total <- as.double(spamdata$caps_len_total)
spamdata <- spamdata %>% dplyr::select(spam,everything())
spamdata$spam <- as.factor(ifelse(spamdata$spam==1,"Y","N"))
# set working directory and import data
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
spamdata <- read.csv("spambase.data", header=FALSE)
dim(spamdata)
glimpse(spamdata)
# Find NA per Column
if (sum(is.na(spamdata)) == 0) {
print(paste("The count of NA in dataset =", sum(is.na(spamdata))))
} else {
cnt <- ncol(spamdata)
for (i in 1:cnt) {
print(colnames(spamdata)[i])
print(sum(is.na(spamdata[,i])))
}
}
View(spamdata)
str(newnames)
type(newnames)
summary(newnames)
class(newnames)
View(spamdata)
#create a list of variable names
newnames <- c("freq_make", "freq_address", "freq_all", "freq_3d", "freq_our", "freq_over", "freq_remove", "freq_internet",
"freq_order", "freq_mail", "freq_receive", "freq_will", "freq_people", "freq_report", "freq_addresses", "freq_free",
"freq_business", "freq_email", "freq_you", "freq_credit", "freq_your", "freq_font", "freq_000", "freq_money",
"freq_hp", "freq_hpl", "freq_george", "freq_650", "freq_lab", "freq_labs", "freq_telnet", "freq_857",
"freq_data", "freq_415", "freq_85", "freq_technology", "freq_1999", "freq_parts", "freq_pm", "freq_direct",
"freq_vcs", "freq_meeting", "freq_original", "freq_project", "freq_re", "freq_edu", "freq_table", "freq_conference",
"freq_semicolon", "freq_parentheses", "freq_bracket", "freq_exclamation_point", "freq_dollar_sign", "freq_pound_sign",
"caps_len_average", "caps_len_longest", "caps_len_total", "spam")
# set the variable names
names(spamdata) <- newnames
# tidy the data
spamdata$caps_len_longest <- as.double(spamdata$caps_len_longest)
spamdata$caps_len_total <- as.double(spamdata$caps_len_total)
spamdata <- spamdata %>% dplyr::select(spam,everything())
spamdata$spam <- as.factor(ifelse(spamdata$spam==1,"Y","N"))
View(spamdata)
glimpse(spamdata)
names(spamdata)
table(spamdata$spam)
#manually look for outliers
# standard deviation methods
# 2 SD beyond the mean covers 95% of a normally distributed variable
# 3 SD +/- the mean covers 99.7% of a normally distributed variable
for (i in 2:ncol(spamdata)){
temp <- spamdata[,i] > (mean(spamdata[,i] + 3*sd(spamdata[,i])))
temp2 <- round(table(temp)[2]/nrow(spamdata) * 100,2)
temp2
print(paste(temp2, "pecent of the", names(spamdata)[i], "data exceeds 3 SD from the mean"))
}
#sapply(dat_num, function(d) (d > (mean(d) + 2*sd(d))))
#sapply(dat_num, function(d) which(d > (mean(d) + 2*sd(d))))
#Rescale the numeric data
spamdata2 <- spamdata
rescale_x <- function(x){(x-min(x))/(max(x)-min(x))}
for (i in 2:ncol(spamdata)){
spamdata2[[i]] <- rescale_x(spamdata[[i]])
}
summary(spamdata2)
# Create Histograms
for (i in 2:ncol(spamdata)){
assign(paste0("h", i), ggplot(data= spamdata, aes_string(colnames(spamdata)[i], fill=spamdata$spam)) + geom_histogram() + #ggtitle(names(spamdata2[i])) +
theme_bw()+ theme(plot.title = element_text(hjust = 0.5)))
}
grid.arrange(h2, h3, h4, h5, h6, h7, h8, h9, h10, h11,
h12, h13, h14, h15, h16, h17, h18, h19, h20, h21,
h22, h23, h24, h25, h26, h27, h28, h29, h30, h31,
h32, h33, h34, h35, h36, h37, h38, h39, h40, h41,
h42, h43, h44, h45, h46, h47, h48, h49, h50, h51,
h52, h53, h54, h55, h56, h57, h58,
ncol=2,
top=textGrob(expression(bold(underline("Histograms"))),
gp=gpar(fontsize=20,font=3)))
# Create Boxplots
for (i in 2:ncol(spamdata)){
assign(paste0("p", i),
ggplot( data = spamdata,
aes_string(x = names(spamdata[1]),
y = names(spamdata[i]),
fill = spamdata$spam)) +
geom_boxplot() + coord_flip() +
theme_bw()+
theme(plot.title = element_text(hjust = 1.5)))
}
grid.arrange(p2, p3, p4, p5, p6, p7, p8, p9, p10, p11,
p12, p13, p14, p15, p16, p17, p18, p19, p20, p21,
p22, p23, p24, p25, p26, p27, p28, p29, p30, p31,
p32, p33, p34, p35, p36, p37, p38, p39, p40, p41,
p42, p43, p44, p45, p46, p47, p48, p49, p50, p51,
p52, p53, p54, p55, p56, p57, p58,
ncol=2,
top=textGrob(expression(bold(underline("Boxplots"))),
gp=gpar(fontsize=20,font=3)))
# random seed
SEED <- 0
# training replications
REPS <- 50
# train-test split ratio
RATIO <- 0.6
# number of trees
NTREE <- 100
###########################################################
# Generic wrapper function for training and prediction
#
# @param name
#     name of the model e.g. "Decision Tree"
# @param build_model
#     function to perform the model-specific training
#     e.g. build_model <- function(data) {
#              return(rpart(Y ~ ., data = data))
#          }
#
# @param split_ratio
#     train to test split ratio e.g. 0.75
#
# @param predict_call
#     variable to control how predict is called
#
# @returns
#     list containing the error % for each rep and the
#     model for each rep
#
###########################################################
train_wrapper <- function(name,
build_model,
split_ratio = 0.6,
predict_call = 1) {
# set random seed to use same data splits
set.seed(SEED)
# vector to store error for each repetition
errors <- rep(0, REPS)
# vector to store models for each repetition
models <- vector(mode = "list", length = REPS)
# vector to store yhat predictions for each repetition
yhats <- vector(mode = "list", length = REPS)
# vector to store test sets
tests <- vector(mode = "list", length = REPS)
for (r in 1:length(errors)) {
# split data for train and test
id = holdout(spamdata$spam, ratio=split_ratio, mode='stratified')
train <- spamdata[id$tr,]
test <- spamdata[id$ts,]
tests[[r]] <- test
# build model on training set
model <- build_model(train)
# store model
models[[r]] <- model
# predict on test set
yhat <- switch (predict_call,
predict(model, test %>% dplyr::select(-spam), type = 'class'),
predict(model, test %>% dplyr::select(-spam)),
predict(model, test %>% dplyr::select(-spam))$class)
# store predictions
yhats[[r]] <- yhat
# store error
errors[r] <- mean(yhat != test$spam)
# print progress
cat(name, "[rep]:", r, "[error]:", errors[r], "\n")
}
# print confusion matrix for most accurate model
index <- which.min(errors)
print(confusionMatrix(table(yhats[[index]], tests[[index]]$spam)))
return(list("errors" = errors, "models" = models))
}
build_regular_tree <- function(training_data) {
rpart(spam ~ ., data = training_data)
}
regular_tree_errors <- train_wrapper("Regular Trees", build_regular_tree)
build_bagged_tree <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
mtry = ncol(training_data) - 1,
ntree = NTREE)
return(model)
}
bagged_tree_errors <- train_wrapper("Bagged Trees", build_bagged_tree)
build_rf <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
mtry = sqrt(ncol(training_data) - 1),
ntree = NTREE)
return(model)
}
rf_errors <- train_wrapper("Random Forest", build_rf)
build_weighted_rf <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
ntree = NTREE,
classwt = c(.8, .9))
return(model)
}
weighted_rf_errors <- train_wrapper("Weighted Random Forest", build_weighted_rf)
build_balanced_rf <- function(training_data) {
minority_class_size <- min(table(training_data$spam))
model <- randomForest(spam ~ .,
data = training_data,
ntree = NTREE,
sampsize = minority_class_size)
return(model)
}
balanced_rf_errors <- train_wrapper("Balanced Random Forest", build_balanced_rf)
build_lda <- function(training_data) {
model <- lda(spam ~ ., data = training_data)
return(model)
}
lda_errors <- train_wrapper("LDA",
build_lda,
split_ratio = RATIO,
predict_call = 3)$errors
build_csvm <- function(training_data) {
model <- svm(spam ~ ., data = training_data, type = "C-classification")
return(model)
}
csvm_errors <- train_wrapper("C-SVM",
build_csvm,
split_ratio = RATIO)$errors
build_nusvm <- function(training_data) {
model <- svm(spam ~ ., data = training_data, type = "nu-classification")
return(model)
}
nusvm_errors <- train_wrapper("nu-SVM",
build_nusvm,
split_ratio = RATIO)$errors
# aggregate to data frame
combined_errors <- as.tibble(data.frame(
Regular = regular_tree_errors$errors,
Bagged = bagged_tree_errors$errors,
RF = rf_errors$errors,
Weighted_RF = weighted_rf_errors$errors,
Balanced_RF = balanced_rf_errors$errors,
LDA = lda_errors,
CSVM = csvm_errors,
NUSVM = nusvm_errors))
# plot errors
combined_errors %>%
melt(measure.vars = c("Regular", "Bagged", "RF", "Weighted_RF", "Balanced_RF", "LDA", "CSVM",
"NUSVM")) %>%
ggplot(aes(x = variable, y = value)) + geom_boxplot() + ggtitle("Classification Errors") +
xlab("Classifier") + ylab("Error %")
# set control
control <- trainControl(method = 'cv', number = 5)
# retrain the model
RF_tune_model <- train(spam ~ ., data = spamdata, method = 'rf', trControl = control,
tuneLength = 5)
# summarize the model
print(RF_tune_model)
# calculate accuracy of the 'regular' weighted random forest run earlier
mean(weighted_rf_errors$errors)
1 - mean(weighted_rf_errors$errors)
# Use optimal value of C below to re-run SVM
csvm_spam =   ksvm(spam~., data=spamdata, cross=5, C= 27,
type='C-svc')
y_hat_csvm = predict(csvm_spam, spamdata[,-1])
mean(y_hat_csvm!=spamdata[,1])
build_qda <- function(training_data) {
model <- qda(spam ~ ., data = training_data)
return(model)
}
qda_errors <- train_wrapper("QDA",
build_qda,
split_ratio = RATIO,
predict_call = 3)$errors
build_linear_model <- function(training_data) {
lm(spam ~ ., data = training_data)
}
linear_model_errors <- train_wrapper("Linear Model", build_linear_model)
spamdata %>%
na.omit() %>%
data.matrix() %>% # use a numeric matrix representation of the data
cor() %>%
psych::nfactors()
psych::fa.parallel(data.matrix(spamdata), fa = "fa", n.iter = 100)
spamdata %>%
na.omit() %>%
data.matrix() %>%
cor() %>%
ggcorrplot(type = "lower")
spamdata %>%
na.omit() %>%
data.matrix() %>%
cor() %>%
ggcorrplot::ggcorrplot(type = "lower")
#Start Fresh
rm(list=ls())
#Load libraries
library(tidyverse)
library(plm)
library(tidyr)
library(ggplot2)
library(scales)
library(readstata13)
library(corrplot)
library(reshape)
library(dplyr)
library(corrplot)
library(gridExtra)
library(rpart)
library(partykit)
library(caret)
library(mlbench)
library(tidyverse)
library(rminer)
library(randomForest)
library(reshape2)
library(MASS)
library(e1071)
library(wsrf)
library(kernlab)
# set working directory and import data
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
spamdata <- read.csv("spambase.data", header=FALSE)
dim(spamdata)
glimpse(spamdata)
# Find NA per Column
if (sum(is.na(spamdata)) == 0) {
print(paste("The count of NA in dataset =", sum(is.na(spamdata))))
} else {
cnt <- ncol(spamdata)
for (i in 1:cnt) {
print(colnames(spamdata)[i])
print(sum(is.na(spamdata[,i])))
}
}
#create a list of variable names
newnames <- c("freq_make", "freq_address", "freq_all", "freq_3d", "freq_our", "freq_over", "freq_remove", "freq_internet",
"freq_order", "freq_mail", "freq_receive", "freq_will", "freq_people", "freq_report", "freq_addresses", "freq_free",
"freq_business", "freq_email", "freq_you", "freq_credit", "freq_your", "freq_font", "freq_000", "freq_money",
"freq_hp", "freq_hpl", "freq_george", "freq_650", "freq_lab", "freq_labs", "freq_telnet", "freq_857",
"freq_data", "freq_415", "freq_85", "freq_technology", "freq_1999", "freq_parts", "freq_pm", "freq_direct",
"freq_vcs", "freq_meeting", "freq_original", "freq_project", "freq_re", "freq_edu", "freq_table", "freq_conference",
"freq_semicolon", "freq_parentheses", "freq_bracket", "freq_exclamation_point", "freq_dollar_sign", "freq_pound_sign",
"caps_len_average", "caps_len_longest", "caps_len_total", "spam")
# set the variable names
names(spamdata) <- newnames
# tidy the data
spamdata$caps_len_longest <- as.double(spamdata$caps_len_longest)
spamdata$caps_len_total <- as.double(spamdata$caps_len_total)
spamdata <- spamdata %>% dplyr::select(spam,everything())
spamdata$spam <- as.factor(ifelse(spamdata$spam==1,"Y","N"))
glimpse(spamdata)
names(spamdata)
obliqueRotation_1f = fa(r = data.matrix(spamdata), nfactors = 3, rotate = "varimax")
obliqueRotation_1f = psych::fa(r = data.matrix(spamdata), nfactors = 3, rotate = "varimax")
obliqueRotation_1f
obliqueRotation_1f$loadings
spamdata %>%
select(-spam)
spamdata %>%
dplyr::select(-spam)
na.omit() %>%
data.matrix() %>% # use a numeric matrix representation of the data
cor() %>%
psych::nfactors()
spamdata %>%
dplyr::select(-spam) %>%
na.omit() %>%
data.matrix() %>% # use a numeric matrix representation of the data
cor() %>%
psych::nfactors()
spamdata %>%
dplyr::select(-spam) %>%
data.matrix() %>%
psych::fa.parallel(.,fa = "fa", n.iter = 100)
spamdata %>%
dplyr::select(-spam) %>%
na.omit() %>%
data.matrix() %>%
cor() %>%
ggcorrplot::ggcorrplot(type = "lower")
obliqueRotation_1f = spamdata %>%
dplyr::select(-spam) %>%
data.matrix() %>%
psych::fa(., nfactors = 3, rotate = "varimax")
obliqueRotation_1f$loadings
obliqueRotation_20f = spamdata %>%
dplyr::select(-spam) %>%
data.matrix() %>%
psych::fa(., nfactors = 20, rotate = "varimax")
obliqueRotation_20f$loadings
obliqueRotation_3f = spamdata %>%
dplyr::select(-spam) %>%
data.matrix() %>%
psych::fa(., nfactors = 3, rotate = "varimax")
obliqueRotation_3f$loadings
obliqueRotation_3f$score.cor
