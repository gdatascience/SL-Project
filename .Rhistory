yhats <- vector(mode = "list", length = REPS)
# vector to store test sets
tests <- vector(mode = "list", length = REPS)
for (r in 1:length(errors)) {
# split data for train and test
id = holdout(spamdata$spam, ratio=split_ratio, mode='stratified')
train <- spamdata[id$tr,]
test <- spamdata[id$ts,]
tests[[r]] <- test
# build model on training set
model <- build_model(train)
# store model
models[[r]] <- model
# predict on test set
yhat <- switch (predict_call,
predict(model, test %>% dplyr::select(-spam), type = 'class'),
predict(model, test %>% dplyr::select(-spam)),
predict(model, test %>% dplyr::select(-spam))$class)
# store predictions
yhats[[r]] <- yhat
# store error
errors[r] <- mean(yhat != test$spam)
# print progress
cat(name, "[rep]:", r, "[error]:", errors[r], "\n")
}
# print confusion matrix for most accurate model
index <- which.min(errors)
print(confusionMatrix(table(yhats[[index]], tests[[index]]$spam)))
return(list("errors" = errors, "models" = models))
}
# Use optimal value of C below to re-run SVM
csvm_spam =   ksvm(spam~., data=spamdata, cross=5, C= 27,
type='C-svc')
y_hat_csvm = predict(csvm_spam, spamdata[,-1])
1-mean(y_hat_csvm!=spamdata[,1])
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
#  Create a sequence to try some values
v.w1 = c(0.01, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1)
v.w2 = c(0.01, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1)
cv.for.w = matrix(0, ncol=length(v.w1), nrow=length(v.w2))
colnames(cv.for.w) = v.w1
rownames(cv.for.w) = v.w2
id = holdout(spamdata$spam, ratio=.6, mode='stratified')
sd.tr = spamdata[id$tr,]
sd.te = spamdata[id$ts,]
for(j in 1:length(v.w1))
{
for(i in 1:length(v.w2))
{
# loop through each value of w to try
w.wrf.xy = randomForest(spam~., data=sd.tr, ntree = 50, classwt=c(v.w1[j],v.w2[i]))
# get the cross validation error for each w value
yhat_twrf = predict(w.wrf.xy, sd.te[,-1])
cv.for.w[j,i] = mean(yhat_twrf!=sd.te[,1])
}
}
# find the optimal weight values
twrf.opt.err = min(cv.for.w)
min.err = which(cv.for.w == opt.err, arr.ind = TRUE)
# find the optimal weight values
twrf.opt.err = min(cv.for.w)
w1.opt = v.w1[min.err[1]]
min.err = which(cv.for.w == twrf.opt.err, arr.ind = TRUE)
w1.opt = v.w1[min.err[1]]
w2.opt = v.w2[min.err[2]]
1-twrf.opt.err
#load the tuned random forest model data
load(file='Weight_RF_tune_model.rdata')
# summarize the model
print(Weight_RF_tune_model)
#load all of the error data
load(file='regular_tree_errors.rdata')
load(file='bagged_tree_errors.rdata')
load(file='rf_errors.rdata')
load(file='weighted_rf_errors.rdata')
load(file='balanced_rf_errors.rdata')
load(file='lda_errors.rdata')
load(file='csvm_errors.rdata')
load(file='nusvm_errors.rdata')
# aggregate to data frame
combined_errors <- as.tibble(data.frame(
Regular = regular_tree_errors$errors,
Bagged = bagged_tree_errors$errors,
RF = rf_errors$errors,
Weighted_RF = weighted_rf_errors$errors,
Balanced_RF = balanced_rf_errors$errors,
LDA = lda_errors,
CSVM = csvm_errors,
NUSVM = nusvm_errors))
# plot errors
combined_errors %>%
melt(measure.vars = c("Regular", "Bagged", "RF", "Weighted_RF", "Balanced_RF", "LDA", "CSVM",
"NUSVM")) %>%
ggplot(aes(x = variable, y = value)) + geom_boxplot() + ggtitle("Classification Errors") +
xlab("Classifier") + ylab("Error %")
build_weighted_rf <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
ntree = NTREE,
classwt = c(.3, .8)) # c(.8, .9))
return(model)
}
weighted_rf_errors <- train_wrapper("Weighted Random Forest", build_weighted_rf)
build_weighted_rf <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
ntree = NTREE,
classwt = c(.8, .3)) # 0.9598
return(model)
}
weighted_rf_errors <- train_wrapper("Weighted Random Forest", build_weighted_rf)
build_weighted_rf <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
ntree = NTREE,
classwt = c(.01, 1))
return(model)
}
weighted_rf_errors <- train_wrapper("Weighted Random Forest", build_weighted_rf)
#store weighted random forest error data as RData files
save(weighted_rf_errors, file='weighted_rf_errors.rdata')
build_weighted_rf <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
ntree = NTREE,
classwt = c(1, .01)) #0.9429
return(model)
}
weighted_rf_errors <- train_wrapper("Weighted Random Forest", build_weighted_rf)
#store weighted random forest error data as RData files
save(weighted_rf_errors, file='weighted_rf_errors.rdata')
# aggregate to data frame
combined_errors <- as.tibble(data.frame(
Regular = regular_tree_errors$errors,
Bagged = bagged_tree_errors$errors,
RF = rf_errors$errors,
Weighted_RF = weighted_rf_errors$errors,
Balanced_RF = balanced_rf_errors$errors,
LDA = lda_errors,
CSVM = csvm_errors,
NUSVM = nusvm_errors))
# plot errors
combined_errors %>%
melt(measure.vars = c("Regular", "Bagged", "RF", "Weighted_RF", "Balanced_RF", "LDA", "CSVM",
"NUSVM")) %>%
ggplot(aes(x = variable, y = value)) + geom_boxplot() + ggtitle("Classification Errors") +
xlab("Classifier") + ylab("Error %")
build_weighted_rf <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
ntree = NTREE,
classwt = c(0.3, 0.8))
return(model)
}
weighted_rf_errors <- train_wrapper("Weighted Random Forest", build_weighted_rf)
build_weighted_rf <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
ntree = NTREE,
classwt = c(0.8, 0.3)) #0.9598
return(model)
}
weighted_rf_errors <- train_wrapper("Weighted Random Forest", build_weighted_rf)
build_weighted_rf <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
ntree = NTREE,
classwt = c(0.3, 0.8))
return(model)
}
weighted_rf_errors <- train_wrapper("Weighted Random Forest", build_weighted_rf)
#store weighted random forest error data as RData files
save(weighted_rf_errors, file='weighted_rf_errors.rdata')
# aggregate to data frame
combined_errors <- as.tibble(data.frame(
Regular = regular_tree_errors$errors,
Bagged = bagged_tree_errors$errors,
RF = rf_errors$errors,
Weighted_RF = weighted_rf_errors$errors,
Balanced_RF = balanced_rf_errors$errors,
LDA = lda_errors,
CSVM = csvm_errors,
NUSVM = nusvm_errors))
# plot errors
combined_errors %>%
melt(measure.vars = c("Regular", "Bagged", "RF", "Weighted_RF", "Balanced_RF", "LDA", "CSVM",
"NUSVM")) %>%
ggplot(aes(x = variable, y = value)) + geom_boxplot() + ggtitle("Classification Errors") +
xlab("Classifier") + ylab("Error %")
#load the tuned random forest model data
load(file='RF_tune_model.rdata')
# summarize the model
print(RF_tune_model)
mod_names = c('RF', 'RF_Opt',
'WRF', 'WRF_Opt',
'CSVM', 'CSVM_Opt')
mod_acrcy = c(1 - mean(rf_errors$errors), 1 - mean(RF_tune_model$finalModel$err.rate),
1 - mean(weighted_rf_errors$errors), 1-twrf.opt.err,
1 - mean(csvm_errors), 1 - mean(y_hat_csvm!=spamdata[,1]))
mod_type = c(1,1,2,2,3,3)
err_comp = data.frame(cbind(mod_names, mod_acrcy, mod_type))
ggplot(err_comp, aes(x = mod_names, y = mod_acrcy, fill = mod_type)) + geom_col()
1 - mean(RF_tune_model$finalModel$err.rate
;
1 - mean(RF_tune_model$finalModel$err.rate)
mod_names = c('RF', 'RF_Opt',
'WRF', 'WRF_Opt',
'CSVM', 'CSVM_Opt')
mod_acrcy = c(1 - mean(rf_errors$errors), 0.9502259,
1 - mean(weighted_rf_errors$errors), 1-twrf.opt.err,
1 - mean(csvm_errors), 1 - mean(y_hat_csvm!=spamdata[,1]))
mod_type = c(1,1,2,2,3,3)
err_comp = data.frame(cbind(mod_names, mod_acrcy, mod_type))
ggplot(err_comp, aes(x = mod_names, y = mod_acrcy, fill = mod_type)) + geom_col()
ggplot(err_comp, aes(x = mod_names, y = mod_acrcy, fill = mod_type)) + geom_col()
# calculate accuracy of the 'regular' weighted random forest run earlier
mean(weighted_rf_errors$errors)
1 - mean(weighted_rf_errors$errors)
#  Create a sequence to try some values
v.w1 = c(0.01, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1)
v.w2 = c(0.01, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1)
cv.for.w = matrix(0, ncol=length(v.w1), nrow=length(v.w2))
colnames(cv.for.w) = v.w1
rownames(cv.for.w) = v.w2
# set random seed to use same data splits
set.seed(SEED)
id = holdout(spamdata$spam, ratio=.6, mode='stratified')
sd.tr = spamdata[id$tr,]
sd.te = spamdata[id$ts,]
for(j in 1:length(v.w1))
{
for(i in 1:length(v.w2))
{
# loop through each value of w to try
w.wrf.xy = randomForest(spam~., data=sd.tr, ntree = 50, classwt=c(v.w1[j],v.w2[i]))
# get the cross validation error for each w value
yhat_twrf = predict(w.wrf.xy, sd.te[,-1])
cv.for.w[j,i] = mean(yhat_twrf!=sd.te[,1])
}
}
# find the optimal weight values
twrf.opt.err = min(cv.for.w)
min.err = which(cv.for.w == twrf.opt.err, arr.ind = TRUE)
w1.opt = v.w1[min.err[1]]
w2.opt = v.w2[min.err[2]]
1-twrf.opt.err
mod_names = c('RF', 'RF_Opt',
'WRF', 'WRF_Opt',
'CSVM', 'CSVM_Opt')
mod_acrcy = c(1 - mean(rf_errors$errors), 0.9502259,
1 - mean(weighted_rf_errors$errors), 1-twrf.opt.err,
1 - mean(csvm_errors), 1 - mean(y_hat_csvm!=spamdata[,1]))
mod_type = c(1,1,2,2,3,3)
err_comp = data.frame(cbind(mod_names, mod_acrcy, mod_type))
ggplot(err_comp, aes(x = mod_names, y = mod_acrcy, fill = mod_type)) + geom_col()
#Load libraries
library(tidyverse)
library(plm)
library(tidyr)
library(ggplot2)
library(scales)
library(readstata13)
library(corrplot)
library(reshape)
library(dplyr)
library(corrplot)
library(gridExtra)
library(rpart)
library(partykit)
library(caret)
library(mlbench)
library(tidyverse)
library(rminer)
library(randomForest)
library(reshape2)
library(MASS)
library(e1071)
library(wsrf)
library(kernlab)
# set working directory and import data
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
spamdata <- read.csv("spambase.data", header=FALSE)
dim(spamdata)
glimpse(spamdata)
# Create Histograms
for (i in 2:ncol(spamdata)){
assign(paste0("h", i), ggplot(data= spamdata, aes_string(colnames(spamdata)[i], fill=spamdata$spam)) + geom_histogram() + #ggtitle(names(spamdata[i])) +
theme_bw()+ theme(plot.title = element_text(hjust = 0.5)))
}
grid.arrange(h2, h3, h4, h5, h6, h7, h8, h9, h10, h11,
h12, h13, h14, h15, h16, h17, h18, h19, h20, h21,
h22, h23, h24, h25, h26, h27, h28, h29, h30, h31,
h32, h33, h34, h35, h36, h37, h38, h39, h40, h41,
h42, h43, h44, h45, h46, h47, h48, h49, h50, h51,
h52, h53, h54, h55, h56, h57, h58,
ncol=2,
top=textGrob(expression(bold(underline("Histograms"))),
gp=gpar(fontsize=20,font=3)))
#create a list of variable names
newnames <- c("freq_make", "freq_address", "freq_all", "freq_3d", "freq_our", "freq_over", "freq_remove", "freq_internet",
"freq_order", "freq_mail", "freq_receive", "freq_will", "freq_people", "freq_report", "freq_addresses", "freq_free",
"freq_business", "freq_email", "freq_you", "freq_credit", "freq_your", "freq_font", "freq_000", "freq_money",
"freq_hp", "freq_hpl", "freq_george", "freq_650", "freq_lab", "freq_labs", "freq_telnet", "freq_857",
"freq_data", "freq_415", "freq_85", "freq_technology", "freq_1999", "freq_parts", "freq_pm", "freq_direct",
"freq_vcs", "freq_meeting", "freq_original", "freq_project", "freq_re", "freq_edu", "freq_table", "freq_conference",
"freq_semicolon", "freq_parentheses", "freq_bracket", "freq_exclamation_point", "freq_dollar_sign", "freq_pound_sign",
"caps_len_average", "caps_len_longest", "caps_len_total", "spam")
# set the variable names
names(spamdata) <- newnames
# tidy the data
spamdata$caps_len_longest <- as.double(spamdata$caps_len_longest)
spamdata$caps_len_total <- as.double(spamdata$caps_len_total)
spamdata <- spamdata %>% dplyr::select(spam,everything())
spamdata$spam <- as.factor(ifelse(spamdata$spam==1,"Y","N"))
# Create Histograms
for (i in 2:ncol(spamdata)){
assign(paste0("h", i), ggplot(data= spamdata, aes_string(colnames(spamdata)[i], fill=spamdata$spam)) + geom_histogram() + #ggtitle(names(spamdata[i])) +
theme_bw()+ theme(plot.title = element_text(hjust = 0.5)))
}
grid.arrange(h2, h3, h4, h5, h6, h7, h8, h9, h10, h11,
h12, h13, h14, h15, h16, h17, h18, h19, h20, h21,
h22, h23, h24, h25, h26, h27, h28, h29, h30, h31,
h32, h33, h34, h35, h36, h37, h38, h39, h40, h41,
h42, h43, h44, h45, h46, h47, h48, h49, h50, h51,
h52, h53, h54, h55, h56, h57, h58,
ncol=2,
top=textGrob(expression(bold(underline("Histograms"))),
gp=gpar(fontsize=20,font=3)))
ggplot(spamdata %>% filter(freq_dollar_sign > 0), aes(freq_dollar_sign, fill=spamdata$spam)) + geom_histogram()
ggplot(spamdata %>% filter(freq_dollar_sign > 0), aes(freq_dollar_sign, fill=spam)) + geom_histogram()
ggplot(spamdata %>% filter(freq_dollar_sign > 0), aes(freq_dollar_sign, fill=spam)) + geom_histogram(binwidth = 1)
summary(spamdata %>% filter(freq_dollar_sign > 0))
summary(spamdata %>% filter(freq_dollar_sign > 0) %>% select(freq_dollar_sign, spam))
summary(spamdata %>% filter(freq_dollar_sign > 0) %>% dplyr::select(freq_dollar_sign, spam))
table(spamdata %>% filter(freq_dollar_sign > 0) %>% dplyr::select(freq_dollar_sign, spam))
#Load libraries
library(tidyverse)
library(plm)
library(tidyr)
library(ggplot2)
library(scales)
library(readstata13)
library(corrplot)
library(reshape)
library(dplyr)
library(corrplot)
library(gridExtra)
library(rpart)
library(partykit)
library(caret)
library(mlbench)
library(tidyverse)
library(rminer)
library(randomForest)
library(reshape2)
library(MASS)
library(e1071)
library(wsrf)
library(kernlab)
# set working directory and import data
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
spamdata <- read.csv("spambase.data", header=FALSE)
dim(spamdata)
#create a list of variable names
newnames <- c("freq_make", "freq_address", "freq_all", "freq_3d", "freq_our", "freq_over", "freq_remove", "freq_internet",
"freq_order", "freq_mail", "freq_receive", "freq_will", "freq_people", "freq_report", "freq_addresses", "freq_free",
"freq_business", "freq_email", "freq_you", "freq_credit", "freq_your", "freq_font", "freq_000", "freq_money",
"freq_hp", "freq_hpl", "freq_george", "freq_650", "freq_lab", "freq_labs", "freq_telnet", "freq_857",
"freq_data", "freq_415", "freq_85", "freq_technology", "freq_1999", "freq_parts", "freq_pm", "freq_direct",
"freq_vcs", "freq_meeting", "freq_original", "freq_project", "freq_re", "freq_edu", "freq_table", "freq_conference",
"freq_semicolon", "freq_parentheses", "freq_bracket", "freq_exclamation_point", "freq_dollar_sign", "freq_pound_sign",
"caps_len_average", "caps_len_longest", "caps_len_total", "spam")
# set the variable names
names(spamdata) <- newnames
# tidy the data
spamdata$caps_len_longest <- as.double(spamdata$caps_len_longest)
spamdata$caps_len_total <- as.double(spamdata$caps_len_total)
spamdata <- spamdata %>% dplyr::select(spam,everything())
spamdata$spam <- as.factor(ifelse(spamdata$spam==1,"Y","N"))
# Create Boxplots
for (i in 2:ncol(spamdata)){
assign(paste0("p", i),
ggplot( data = spamdata,
aes_string(x = names(spamdata[1]),
y = names(spamdata[i]),
fill = spamdata$spam)) +
geom_boxplot() + coord_flip() +
theme_bw()+
theme(plot.title = element_text(hjust = 1.5)))
}
# Create Boxplots
for (i in 2:ncol(spamdata)){
assign(paste0("p", i),
ggplot( data = spamdata,
aes_string(x = names(spamdata[1]),
y = names(spamdata[i]),
fill = spamdata$spam)) +
geom_boxplot() + coord_flip() +
theme_bw()+
theme(plot.title = element_text(hjust = 1.5)))
}
grid.arrange(p2, p3, p4, p5, p6, p7, p8, p9, p10, p11,
p12, p13, p14, p15, p16, p17, p18, p19, p20, p21,
p22, p23, p24, p25, p26, p27, p28, p29, p30, p31,
p32, p33, p34, p35, p36, p37, p38, p39, p40, p41,
p42, p43, p44, p45, p46, p47, p48, p49, p50, p51,
p52, p53, p54, p55, p56, p57, p58,
ncol=2,
top=textGrob(expression(bold(underline("Boxplots"))),
gp=gpar(fontsize=20,font=3)))
#Rescale the numeric data
spamdata2 <- spamdata
rescale_x <- function(x){(x-min(x))/(max(x)-min(x))}
for (i in 2:ncol(spamdata)){
spamdata2[[i]] <- rescale_x(spamdata[[i]])
}
#Rescale the numeric data
spamdata2 <- spamdata
rescale_x <- function(x){(x-min(x))/(max(x)-min(x))}
for (i in 2:ncol(spamdata)){
spamdata2[[i]] <- rescale_x(spamdata[[i]])
}
spamdata_unscaled <- spamdata
spamdata <- spamdata2
SEED <- 0 # random seed
REPS <- 50 # training replications
RATIO <- 0.6 # train-test split ratio
NTREE <- 100 # number of trees
###########################################################
# Generic wrapper function for training and prediction
#
# @param name
#     name of the model e.g. "Decision Tree"
# @param build_model
#     function to perform the model-specific training
#     e.g. build_model <- function(data) {
#              return(rpart(Y ~ ., data = data))
#          }
#
# @param split_ratio
#     train to test split ratio e.g. 0.75
#
# @param predict_call
#     variable to control how predict is called
#
# @returns
#     list containing the error % for each rep and the
#     model for each rep
#
###########################################################
train_wrapper <- function(name,
build_model,
split_ratio = 0.6,
predict_call = 1) {
# set random seed to use same data splits
set.seed(SEED)
# vector to store error for each repetition
errors <- rep(0, REPS)
# vector to store models for each repetition
models <- vector(mode = "list", length = REPS)
# vector to store yhat predictions for each repetition
yhats <- vector(mode = "list", length = REPS)
# vector to store test sets
tests <- vector(mode = "list", length = REPS)
for (r in 1:length(errors)) {
# split data for train and test
id = holdout(spamdata$spam, ratio=split_ratio, mode='stratified')
train <- spamdata[id$tr,]
test <- spamdata[id$ts,]
tests[[r]] <- test
# build model on training set
model <- build_model(train)
# store model
models[[r]] <- model
# predict on test set
yhat <- switch (predict_call,
predict(model, test %>% dplyr::select(-spam), type = 'class'),
predict(model, test %>% dplyr::select(-spam)),
predict(model, test %>% dplyr::select(-spam))$class)
# store predictions
yhats[[r]] <- yhat
# store error
errors[r] <- mean(yhat != test$spam)
# print progress
cat(name, "[rep]:", r, "[error]:", errors[r], "\n")
}
# print confusion matrix for most accurate model
index <- which.min(errors)
print(confusionMatrix(table(yhats[[index]], tests[[index]]$spam)))
return(list("errors" = errors, "models" = models))
}
#load all of the error data
load(file='regular_tree_errors.rdata')
load(file='bagged_tree_errors.rdata')
load(file='rf_errors.rdata')
load(file='weighted_rf_errors.rdata')
load(file='balanced_rf_errors.rdata')
load(file='lda_errors.rdata')
load(file='csvm_errors.rdata')
load(file='nusvm_errors.rdata')
mean(weighted_rf_errors$errors)
1 - mean(weighted_rf_errors$errors)
1 - mean(rf_errors$errors)
1 - mean(balanced_rf_errors$errors)
#Cross Validating your C - value
# Number of C to observe
n.c = 20
#  Create a sequence to try out 20 values between 2^-7 and 2^7
v.c = seq(2^(-7),2^7, length=n.c)
v.c
warnings()
