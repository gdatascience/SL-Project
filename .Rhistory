#     main='SVM Optimization',type='b')
#points(x=c.opt,y=min(cv.for.c),col='red',pch=8)
#abline(h=min(cv.for.c),col='red')
View(cv.for.w)
min(which(cv.for.w==min(cv.for.w)))
min(cv.for.w)
min(cv.for.w)$index
indexof(min(cv.for.w))
index(min(cv.for.w))
View(cv.for.w)
which.min(cv.for.w)
colnames(cv.for.w) = v.w1
rownames(cv.for.w) = v.w2
View(cv.for.w)
which(cv.for.w == min(cv.for.w), arr.ind = TRUE)
cv.for.w[5,5]
View(cv.for.w)
# find the optimal weight values
min.err = which(cv.for.w == min(cv.for.w), arr.ind = TRUE)
min.err
w1.opt = min.err[1]
w1.opt = v.w1[min.err[1]]
w2.opt = v.w2[min.err[2]]
min(cv.for.w)
print('Tuned Weighted Random Forest Accuracy: ', 1-opt.err)
# find the optimal weight values
opt.err = min(cv.for.w)
print('Tuned Weighted Random Forest Accuracy: ', 1-opt.err)
1-opt.err
# find the optimal weight values
twrf.opt.err = min(cv.for.w)
1-twrf.opt.err
SEED <- 0 # random seed
REPS <- 50 # training replications
RATIO <- 0.6 # train-test split ratio
NTREE <- 100 # number of trees
###########################################################
# Generic wrapper function for training and prediction
#
# @param name
#     name of the model e.g. "Decision Tree"
# @param build_model
#     function to perform the model-specific training
#     e.g. build_model <- function(data) {
#              return(rpart(Y ~ ., data = data))
#          }
#
# @param split_ratio
#     train to test split ratio e.g. 0.75
#
# @param predict_call
#     variable to control how predict is called
#
# @returns
#     list containing the error % for each rep and the
#     model for each rep
#
###########################################################
train_wrapper <- function(name,
build_model,
split_ratio = 0.6,
predict_call = 1) {
# set random seed to use same data splits
set.seed(SEED)
# vector to store error for each repetition
errors <- rep(0, REPS)
# vector to store models for each repetition
models <- vector(mode = "list", length = REPS)
# vector to store yhat predictions for each repetition
yhats <- vector(mode = "list", length = REPS)
# vector to store test sets
tests <- vector(mode = "list", length = REPS)
for (r in 1:length(errors)) {
# split data for train and test
id = holdout(spamdata$spam, ratio=split_ratio, mode='stratified')
train <- spamdata[id$tr,]
test <- spamdata[id$ts,]
tests[[r]] <- test
# build model on training set
model <- build_model(train)
# store model
models[[r]] <- model
# predict on test set
yhat <- switch (predict_call,
predict(model, test %>% dplyr::select(-spam), type = 'class'),
predict(model, test %>% dplyr::select(-spam)),
predict(model, test %>% dplyr::select(-spam))$class)
# store predictions
yhats[[r]] <- yhat
# store error
errors[r] <- mean(yhat != test$spam)
# print progress
cat(name, "[rep]:", r, "[error]:", errors[r], "\n")
}
# print confusion matrix for most accurate model
index <- which.min(errors)
print(confusionMatrix(table(yhats[[index]], tests[[index]]$spam)))
return(list("errors" = errors, "models" = models))
}
build_qda <- function(training_data) {
model <- qda(spam ~ ., data = training_data)
return(model)
}
qda_errors <- train_wrapper("QDA",
build_qda,
split_ratio = RATIO,
predict_call = 3)$errors
#load regular tree error data
load(file='regular_tree_errors.rdata')
#load bagged tree error data
load(file='bagged_tree_errors.rdata')
#load random forest error data
load(file='rf_errors.rdata')
#load weighted random forest error data
load(file='weighted_rf_errors.rdata')
#load balanced random forest error data
load(file='balanced_rf_errors.rdata')
#load LDA error data
load(file='lda_errors.rdata')
#load C-SVM error data
load(file='csvm_errors.rdata')
#load C-SVM error data
load(file='nusvm_errors.rdata')
# aggregate to data frame
combined_errors <- as.tibble(data.frame(
Regular = regular_tree_errors$errors,
Bagged = bagged_tree_errors$errors,
RF = rf_errors$errors,
Weighted_RF = weighted_rf_errors$errors,
Balanced_RF = balanced_rf_errors$errors,
LDA = lda_errors,
CSVM = csvm_errors,
NUSVM = nusvm_errors))
# plot errors
combined_errors %>%
melt(measure.vars = c("Regular", "Bagged", "RF", "Weighted_RF", "Balanced_RF", "LDA", "CSVM",
"NUSVM")) %>%
ggplot(aes(x = variable, y = value)) + geom_boxplot() + ggtitle("Classification Errors") +
xlab("Classifier") + ylab("Error %")
#load the tuned random forest model data
load(file='RF_tune_model.rdata')
# summarize the model
print(RF_tune_model)
# calculate accuracy of the 'regular' random forest run earlier
mean(rf_errors$errors)
1 - mean(rf_errors$errors)
#load the tuned random forest model data
load(file='Weight_RF_tune_model.rdata')
# summarize the model
print(Weight_RF_tune_model)
# calculate accuracy of the 'regular' weighted random forest run earlier
mean(weighted_rf_errors$errors)
1 - mean(weighted_rf_errors$errors)
# Use optimal value of C below to re-run SVM
csvm_spam =   ksvm(spam~., data=spamdata, cross=5, C= 27,
type='C-svc')
y_hat_csvm = predict(csvm_spam, spamdata[,-1])
mean(y_hat_csvm!=spamdata[,1])
mod_names = c('RF', 'RF_Opt',
'WRF', 'WRF_Opt',
'CSVM', 'CSVM_Opt')
mod_acrcy = c(1 - mean(rf_errors$errors), 1 - mean(RF_tune_model$finalModel$err.rate),
1 - mean(weighted_rf_errors$errors), 1-twrf.opt.err,
1 - mean(csvm_errors), 1 - mean(y_hat_csvm!=spamdata[,1]))
mod_type = c(1,1,2,2,3,3)
err_comp = data.frame(cbind(mod_names, mod_acrcy, mod_type))
ggplot(err_comp, aes(x = mod_names, y = mod_acrcy, fill = mod_type)) + geom_col()
#Load libraries
library(tidyverse)
library(plm)
library(tidyr)
library(ggplot2)
library(scales)
library(readstata13)
library(corrplot)
library(reshape)
library(dplyr)
library(corrplot)
library(gridExtra)
library(rpart)
library(partykit)
library(caret)
library(mlbench)
library(tidyverse)
library(rminer)
library(randomForest)
library(reshape2)
library(MASS)
library(e1071)
library(wsrf)
library(kernlab)
# set working directory and import data
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
spamdata <- read.csv("spambase.data", header=FALSE)
dim(spamdata)
#create a list of variable names
newnames <- c("freq_make", "freq_address", "freq_all", "freq_3d", "freq_our", "freq_over", "freq_remove", "freq_internet",
"freq_order", "freq_mail", "freq_receive", "freq_will", "freq_people", "freq_report", "freq_addresses", "freq_free",
"freq_business", "freq_email", "freq_you", "freq_credit", "freq_your", "freq_font", "freq_000", "freq_money",
"freq_hp", "freq_hpl", "freq_george", "freq_650", "freq_lab", "freq_labs", "freq_telnet", "freq_857",
"freq_data", "freq_415", "freq_85", "freq_technology", "freq_1999", "freq_parts", "freq_pm", "freq_direct",
"freq_vcs", "freq_meeting", "freq_original", "freq_project", "freq_re", "freq_edu", "freq_table", "freq_conference",
"freq_semicolon", "freq_parentheses", "freq_bracket", "freq_exclamation_point", "freq_dollar_sign", "freq_pound_sign",
"caps_len_average", "caps_len_longest", "caps_len_total", "spam")
# set the variable names
names(spamdata) <- newnames
# tidy the data
spamdata$caps_len_longest <- as.double(spamdata$caps_len_longest)
spamdata$caps_len_total <- as.double(spamdata$caps_len_total)
spamdata <- spamdata %>% dplyr::select(spam,everything())
spamdata$spam <- as.factor(ifelse(spamdata$spam==1,"Y","N"))
#Rescale the numeric data
spamdata2 <- spamdata
rescale_x <- function(x){(x-min(x))/(max(x)-min(x))}
for (i in 2:ncol(spamdata)){
spamdata2[[i]] <- rescale_x(spamdata[[i]])
}
spamdata_unscaled <- spamdata
spamdata <- spamdata2
SEED <- 0 # random seed
REPS <- 50 # training replications
RATIO <- 0.6 # train-test split ratio
NTREE <- 100 # number of trees
###########################################################
# Generic wrapper function for training and prediction
#
# @param name
#     name of the model e.g. "Decision Tree"
# @param build_model
#     function to perform the model-specific training
#     e.g. build_model <- function(data) {
#              return(rpart(Y ~ ., data = data))
#          }
#
# @param split_ratio
#     train to test split ratio e.g. 0.75
#
# @param predict_call
#     variable to control how predict is called
#
# @returns
#     list containing the error % for each rep and the
#     model for each rep
#
###########################################################
train_wrapper <- function(name,
build_model,
split_ratio = 0.6,
predict_call = 1) {
# set random seed to use same data splits
set.seed(SEED)
# vector to store error for each repetition
errors <- rep(0, REPS)
# vector to store models for each repetition
models <- vector(mode = "list", length = REPS)
# vector to store yhat predictions for each repetition
yhats <- vector(mode = "list", length = REPS)
# vector to store test sets
tests <- vector(mode = "list", length = REPS)
for (r in 1:length(errors)) {
# split data for train and test
id = holdout(spamdata$spam, ratio=split_ratio, mode='stratified')
train <- spamdata[id$tr,]
test <- spamdata[id$ts,]
tests[[r]] <- test
# build model on training set
model <- build_model(train)
# store model
models[[r]] <- model
# predict on test set
yhat <- switch (predict_call,
predict(model, test %>% dplyr::select(-spam), type = 'class'),
predict(model, test %>% dplyr::select(-spam)),
predict(model, test %>% dplyr::select(-spam))$class)
# store predictions
yhats[[r]] <- yhat
# store error
errors[r] <- mean(yhat != test$spam)
# print progress
cat(name, "[rep]:", r, "[error]:", errors[r], "\n")
}
# print confusion matrix for most accurate model
index <- which.min(errors)
print(confusionMatrix(table(yhats[[index]], tests[[index]]$spam)))
return(list("errors" = errors, "models" = models))
}
# Use optimal value of C below to re-run SVM
csvm_spam =   ksvm(spam~., data=spamdata, cross=5, C= 27,
type='C-svc')
y_hat_csvm = predict(csvm_spam, spamdata[,-1])
1-mean(y_hat_csvm!=spamdata[,1])
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
#  Create a sequence to try some values
v.w1 = c(0.01, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1)
v.w2 = c(0.01, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1)
cv.for.w = matrix(0, ncol=length(v.w1), nrow=length(v.w2))
colnames(cv.for.w) = v.w1
rownames(cv.for.w) = v.w2
id = holdout(spamdata$spam, ratio=.6, mode='stratified')
sd.tr = spamdata[id$tr,]
sd.te = spamdata[id$ts,]
for(j in 1:length(v.w1))
{
for(i in 1:length(v.w2))
{
# loop through each value of w to try
w.wrf.xy = randomForest(spam~., data=sd.tr, ntree = 50, classwt=c(v.w1[j],v.w2[i]))
# get the cross validation error for each w value
yhat_twrf = predict(w.wrf.xy, sd.te[,-1])
cv.for.w[j,i] = mean(yhat_twrf!=sd.te[,1])
}
}
# find the optimal weight values
twrf.opt.err = min(cv.for.w)
min.err = which(cv.for.w == opt.err, arr.ind = TRUE)
# find the optimal weight values
twrf.opt.err = min(cv.for.w)
w1.opt = v.w1[min.err[1]]
min.err = which(cv.for.w == twrf.opt.err, arr.ind = TRUE)
w1.opt = v.w1[min.err[1]]
w2.opt = v.w2[min.err[2]]
1-twrf.opt.err
#load the tuned random forest model data
load(file='Weight_RF_tune_model.rdata')
# summarize the model
print(Weight_RF_tune_model)
#load all of the error data
load(file='regular_tree_errors.rdata')
load(file='bagged_tree_errors.rdata')
load(file='rf_errors.rdata')
load(file='weighted_rf_errors.rdata')
load(file='balanced_rf_errors.rdata')
load(file='lda_errors.rdata')
load(file='csvm_errors.rdata')
load(file='nusvm_errors.rdata')
# aggregate to data frame
combined_errors <- as.tibble(data.frame(
Regular = regular_tree_errors$errors,
Bagged = bagged_tree_errors$errors,
RF = rf_errors$errors,
Weighted_RF = weighted_rf_errors$errors,
Balanced_RF = balanced_rf_errors$errors,
LDA = lda_errors,
CSVM = csvm_errors,
NUSVM = nusvm_errors))
# plot errors
combined_errors %>%
melt(measure.vars = c("Regular", "Bagged", "RF", "Weighted_RF", "Balanced_RF", "LDA", "CSVM",
"NUSVM")) %>%
ggplot(aes(x = variable, y = value)) + geom_boxplot() + ggtitle("Classification Errors") +
xlab("Classifier") + ylab("Error %")
build_weighted_rf <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
ntree = NTREE,
classwt = c(.3, .8)) # c(.8, .9))
return(model)
}
weighted_rf_errors <- train_wrapper("Weighted Random Forest", build_weighted_rf)
build_weighted_rf <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
ntree = NTREE,
classwt = c(.8, .3)) # 0.9598
return(model)
}
weighted_rf_errors <- train_wrapper("Weighted Random Forest", build_weighted_rf)
build_weighted_rf <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
ntree = NTREE,
classwt = c(.01, 1))
return(model)
}
weighted_rf_errors <- train_wrapper("Weighted Random Forest", build_weighted_rf)
#store weighted random forest error data as RData files
save(weighted_rf_errors, file='weighted_rf_errors.rdata')
build_weighted_rf <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
ntree = NTREE,
classwt = c(1, .01)) #0.9429
return(model)
}
weighted_rf_errors <- train_wrapper("Weighted Random Forest", build_weighted_rf)
#store weighted random forest error data as RData files
save(weighted_rf_errors, file='weighted_rf_errors.rdata')
# aggregate to data frame
combined_errors <- as.tibble(data.frame(
Regular = regular_tree_errors$errors,
Bagged = bagged_tree_errors$errors,
RF = rf_errors$errors,
Weighted_RF = weighted_rf_errors$errors,
Balanced_RF = balanced_rf_errors$errors,
LDA = lda_errors,
CSVM = csvm_errors,
NUSVM = nusvm_errors))
# plot errors
combined_errors %>%
melt(measure.vars = c("Regular", "Bagged", "RF", "Weighted_RF", "Balanced_RF", "LDA", "CSVM",
"NUSVM")) %>%
ggplot(aes(x = variable, y = value)) + geom_boxplot() + ggtitle("Classification Errors") +
xlab("Classifier") + ylab("Error %")
build_weighted_rf <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
ntree = NTREE,
classwt = c(0.3, 0.8))
return(model)
}
weighted_rf_errors <- train_wrapper("Weighted Random Forest", build_weighted_rf)
build_weighted_rf <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
ntree = NTREE,
classwt = c(0.8, 0.3)) #0.9598
return(model)
}
weighted_rf_errors <- train_wrapper("Weighted Random Forest", build_weighted_rf)
build_weighted_rf <- function(training_data) {
model <- randomForest(spam ~ .,
data = training_data,
ntree = NTREE,
classwt = c(0.3, 0.8))
return(model)
}
weighted_rf_errors <- train_wrapper("Weighted Random Forest", build_weighted_rf)
#store weighted random forest error data as RData files
save(weighted_rf_errors, file='weighted_rf_errors.rdata')
# aggregate to data frame
combined_errors <- as.tibble(data.frame(
Regular = regular_tree_errors$errors,
Bagged = bagged_tree_errors$errors,
RF = rf_errors$errors,
Weighted_RF = weighted_rf_errors$errors,
Balanced_RF = balanced_rf_errors$errors,
LDA = lda_errors,
CSVM = csvm_errors,
NUSVM = nusvm_errors))
# plot errors
combined_errors %>%
melt(measure.vars = c("Regular", "Bagged", "RF", "Weighted_RF", "Balanced_RF", "LDA", "CSVM",
"NUSVM")) %>%
ggplot(aes(x = variable, y = value)) + geom_boxplot() + ggtitle("Classification Errors") +
xlab("Classifier") + ylab("Error %")
#load the tuned random forest model data
load(file='RF_tune_model.rdata')
# summarize the model
print(RF_tune_model)
mod_names = c('RF', 'RF_Opt',
'WRF', 'WRF_Opt',
'CSVM', 'CSVM_Opt')
mod_acrcy = c(1 - mean(rf_errors$errors), 1 - mean(RF_tune_model$finalModel$err.rate),
1 - mean(weighted_rf_errors$errors), 1-twrf.opt.err,
1 - mean(csvm_errors), 1 - mean(y_hat_csvm!=spamdata[,1]))
mod_type = c(1,1,2,2,3,3)
err_comp = data.frame(cbind(mod_names, mod_acrcy, mod_type))
ggplot(err_comp, aes(x = mod_names, y = mod_acrcy, fill = mod_type)) + geom_col()
1 - mean(RF_tune_model$finalModel$err.rate
;
1 - mean(RF_tune_model$finalModel$err.rate)
mod_names = c('RF', 'RF_Opt',
'WRF', 'WRF_Opt',
'CSVM', 'CSVM_Opt')
mod_acrcy = c(1 - mean(rf_errors$errors), 0.9502259,
1 - mean(weighted_rf_errors$errors), 1-twrf.opt.err,
1 - mean(csvm_errors), 1 - mean(y_hat_csvm!=spamdata[,1]))
mod_type = c(1,1,2,2,3,3)
err_comp = data.frame(cbind(mod_names, mod_acrcy, mod_type))
ggplot(err_comp, aes(x = mod_names, y = mod_acrcy, fill = mod_type)) + geom_col()
ggplot(err_comp, aes(x = mod_names, y = mod_acrcy, fill = mod_type)) + geom_col()
# calculate accuracy of the 'regular' weighted random forest run earlier
mean(weighted_rf_errors$errors)
1 - mean(weighted_rf_errors$errors)
#  Create a sequence to try some values
v.w1 = c(0.01, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1)
v.w2 = c(0.01, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1)
cv.for.w = matrix(0, ncol=length(v.w1), nrow=length(v.w2))
colnames(cv.for.w) = v.w1
rownames(cv.for.w) = v.w2
# set random seed to use same data splits
set.seed(SEED)
id = holdout(spamdata$spam, ratio=.6, mode='stratified')
sd.tr = spamdata[id$tr,]
sd.te = spamdata[id$ts,]
for(j in 1:length(v.w1))
{
for(i in 1:length(v.w2))
{
# loop through each value of w to try
w.wrf.xy = randomForest(spam~., data=sd.tr, ntree = 50, classwt=c(v.w1[j],v.w2[i]))
# get the cross validation error for each w value
yhat_twrf = predict(w.wrf.xy, sd.te[,-1])
cv.for.w[j,i] = mean(yhat_twrf!=sd.te[,1])
}
}
# find the optimal weight values
twrf.opt.err = min(cv.for.w)
min.err = which(cv.for.w == twrf.opt.err, arr.ind = TRUE)
w1.opt = v.w1[min.err[1]]
w2.opt = v.w2[min.err[2]]
1-twrf.opt.err
mod_names = c('RF', 'RF_Opt',
'WRF', 'WRF_Opt',
'CSVM', 'CSVM_Opt')
mod_acrcy = c(1 - mean(rf_errors$errors), 0.9502259,
1 - mean(weighted_rf_errors$errors), 1-twrf.opt.err,
1 - mean(csvm_errors), 1 - mean(y_hat_csvm!=spamdata[,1]))
mod_type = c(1,1,2,2,3,3)
err_comp = data.frame(cbind(mod_names, mod_acrcy, mod_type))
ggplot(err_comp, aes(x = mod_names, y = mod_acrcy, fill = mod_type)) + geom_col()
